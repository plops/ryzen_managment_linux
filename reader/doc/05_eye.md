show python code to display the binned eye diagram for a workload on a core


Of course. Here is a complete Python script to parse the CSV file generated by your C++ program and display a binned eye diagram.

This script uses `pandas` for efficient data manipulation and `matplotlib` for plotting. It's structured as a command-line tool, making it easy to reuse for different cores, sensors, and analysis windows.

### Prerequisites

You'll need to install the required Python libraries:

```bash
pip install pandas matplotlib
```

### `plot_eye_diagram.py`

Create a file named `plot_eye_diagram.py` and paste the following code into it.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import argparse
from pathlib import Path

def plot_eye_diagram(input_file: Path, core_id: int, sensor_name: str, round_id: int,
                     pre_trigger_ms: float, post_trigger_ms: float, bin_size_ms: float):
    """
    Loads measurement data, finds busy-state triggers, and plots a binned
    eye diagram of a sensor's response around those triggers.

    Args:
        input_file: Path to the input CSV file.
        core_id: The specific worker core to analyze.
        sensor_name: The name of the sensor column to plot (e.g., 'sensor1').
        round_id: The specific experiment round to analyze.
        pre_trigger_ms: How many milliseconds of data to show before the trigger.
        post_trigger_ms: How many milliseconds of data to show after the trigger.
        bin_size_ms: The width of each time bin for averaging, in milliseconds.
    """
    print(f"Loading data from '{input_file}'...")
    try:
        df = pd.read_csv(input_file)
    except FileNotFoundError:
        print(f"Error: Input file not found at '{input_file}'")
        return

    # --- 1. Filter Data for the Specific Run ---
    # We use .copy() to avoid SettingWithCopyWarning later on
    run_df = df[(df['core_id'] == core_id) & (df['round'] == round_id)].copy()

    if run_df.empty:
        print(f"Error: No data found for core_id={core_id} and round={round_id}. Please check your inputs.")
        return
        
    print(f"Found {len(run_df)} samples for core {core_id}, round {round_id}.")

    # --- 2. Identify Trigger Events ---
    # A trigger is a transition from worker_state 0 (wait) to 1 (busy).
    # We use .shift(1) to look at the value in the previous row.
    run_df['prev_state'] = run_df['worker_state'].shift(1)
    triggers = run_df[(run_df['worker_state'] == 1) & (run_df['prev_state'] == 0)]
    
    trigger_timestamps_ns = triggers['timestamp_ns'].values
    
    if len(trigger_timestamps_ns) == 0:
        print(f"Error: No wait-to-busy (0 -> 1) transitions found for core {core_id}. Cannot create diagram.")
        return
        
    print(f"Found {len(trigger_timestamps_ns)} busy-state triggers.")

    # --- 3. Collect Data Around Each Trigger (Epochs) ---
    pre_trigger_ns = pre_trigger_ms * 1e6
    post_trigger_ns = post_trigger_ms * 1e6
    
    all_epochs = []
    for t_start in trigger_timestamps_ns:
        # Select all measurement samples within the time window of this trigger
        epoch_df = run_df[
            (run_df['timestamp_ns'] >= t_start - pre_trigger_ns) &
            (run_df['timestamp_ns'] <= t_start + post_trigger_ns)
        ].copy()
        
        # Calculate time relative to the trigger event
        epoch_df['relative_time_ns'] = epoch_df['timestamp_ns'] - t_start
        all_epochs.append(epoch_df)

    if not all_epochs:
        print("Error: Could not extract any valid data epochs around the triggers.")
        return

    # Combine all epochs into a single DataFrame for analysis
    analysis_df = pd.concat(all_epochs)
    analysis_df['relative_time_ms'] = analysis_df['relative_time_ns'] / 1e6

    # --- 4. Bin the Data ---
    # Create time bins from the start to the end of our window
    bin_edges = np.arange(-pre_trigger_ms, post_trigger_ms + bin_size_ms, bin_size_ms)
    
    # Assign each sample to a time bin
    analysis_df['time_bin'] = pd.cut(analysis_df['relative_time_ms'], bins=bin_edges, right=False)
    
    # Group by the time bins and calculate the mean and standard deviation for the sensor
    binned_stats = analysis_df.groupby('time_bin')[sensor_name].agg(['mean', 'std']).reset_index()
    
    # Get a numerical x-value for plotting (the midpoint of each bin)
    binned_stats['bin_midpoint_ms'] = binned_stats['time_bin'].apply(lambda b: b.mid).astype(float)
    binned_stats.dropna(subset=['bin_midpoint_ms'], inplace=True) # Drop any empty bins

    # --- 5. Plot the Diagram ---
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # Plot the mean value for each bin
    ax.plot(
        binned_stats['bin_midpoint_ms'],
        binned_stats['mean'],
        marker='o',
        markersize=4,
        linestyle='-',
        label=f'Mean of {sensor_name}'
    )
    
    # Add a shaded region for +/- 1 standard deviation
    ax.fill_between(
        binned_stats['bin_midpoint_ms'],
        binned_stats['mean'] - binned_stats['std'],
        binned_stats['mean'] + binned_stats['std'],
        alpha=0.2,
        label='Â±1 Standard Deviation',
        color='tab:blue'
    )
    
    # Mark the trigger point at t=0
    ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Workload Start (t=0)')
    
    ax.set_title(f'Binned Eye Diagram: Response of "{sensor_name}" on Core {core_id}', fontsize=16)
    ax.set_xlabel('Time Relative to Workload Start (ms)', fontsize=12)
    ax.set_ylabel(f'Sensor Value ({sensor_name})', fontsize=12)
    ax.grid(True, which='both', linestyle=':', linewidth=0.5)
    ax.legend()
    plt.tight_layout()

    # Save the figure
    output_filename = f"eye_diagram_core_{core_id}_round_{round_id}_{sensor_name}.png"
    plt.savefig(output_filename)
    print(f"\nPlot saved to '{output_filename}'")
    
    plt.show()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Generate a binned eye diagram from workload measurement data.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "input_file",
        type=Path,
        help="Path to the input CSV file generated by the measurement tool."
    )
    parser.add_argument(
        "--core",
        type=int,
        required=True,
        help="The worker core ID to analyze."
    )
    parser.add_argument(
        "--sensor",
        type=str,
        default="sensor1",
        help="The name of the sensor column to plot."
    )
    parser.add_argument(
        "--round",
        type=int,
        default=0,
        help="The experiment round to analyze."
    )
    parser.add_argument(
        "--pre",
        type=float,
        default=10.0,
        help="Time window before the trigger to include (in milliseconds)."
    )
    parser.add_argument(
        "--post",
        type=float,
        default=40.0,
        help="Time window after the trigger to include (in milliseconds)."
    )
    parser.add_argument(
        "--bin-size",
        type=float,
        default=0.5,
        help="Size of each time bin for averaging (in milliseconds)."
    )
    
    args = parser.parse_args()
    
    plot_eye_diagram(
        input_file=args.input_file,
        core_id=args.core,
        sensor_name=args.sensor,
        round_id=args.round,
        pre_trigger_ms=args.pre,
        post_trigger_ms=args.post,
        bin_size_ms=args.bin_size
    )
```

### How to Use

1.  **Run your C++ measurement tool** to generate a results CSV file (e.g., `results/output.csv`).
2.  **Run the Python script from your terminal**, pointing it to the CSV file and specifying the core you want to analyze.

    ```bash
    # Analyze core 3 from the output.csv file
    python plot_eye_diagram.py results/output.csv --core 3

    # Analyze core 5, looking at 'sensor2', with a wider time window
    python plot_eye_diagram.py results/output.csv --core 5 --sensor sensor2 --pre 20 --post 60

    # Analyze core 2 with smaller bins for more detail
    python plot_eye_diagram.py results/output.csv --core 2 --bin-size 0.2
    ```

### Example Output

Running the script will produce and display a plot similar to this, and save it to a PNG file. This example shows a hypothetical sensor value that rises with a delay after the workload begins at t=0.



This visualization clearly shows:
*   The baseline sensor value before the trigger.
*   The point in time where the sensor value begins to react.
*   The ramp-up time and the new steady-state value while the core is busy.
*   The variability (standard deviation) of the measurement at each point in time.